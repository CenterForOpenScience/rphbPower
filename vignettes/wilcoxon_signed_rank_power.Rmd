---
title: "Wilcoxon Signed-Rank Power Analysis"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Wilcoxon Signed-Rank Power Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
devtools::load_all()
```

Power analysis for Wilcoxon signed-rank test using partial correlations within the unified framework with integrated discount factor system and asymptotic relative efficiency adjustments.

## Overview

The Wilcoxon signed-rank test provides a nonparametric alternative to paired t-tests when distributional assumptions are violated. This implementation extends the unified framework to nonparametric testing while maintaining partial correlations as the standardized effect size metric for direct comparison across parametric and nonparametric approaches.

## Key Framework Features

- **Unified Effect Size Metric**: Partial correlations as standard metric for direct comparison
- **Automatic Parameter Detection**: Provide any two of (r_partial, n, power) - the third is calculated
- **Conservative Planning**: Built-in discount factor (default 0.75) for realistic estimates
- **Framework Integration**: Seamless conversion from Cohen's d, f², R², eta-squared
- **Asymptotic Relative Efficiency**: Built-in ARE adjustments for nonparametric efficiency

## Quick Start

```{r setup}
library(rphbPower)
```

```r
# Calculate power (provide r_partial and n)
wilcoxon_signed_rank_power(r_partial = 0.25, n = 40)

# Calculate sample size (provide r_partial and power)
wilcoxon_signed_rank_power(r_partial = 0.20, power = 0.8)

# Calculate effect size (provide n and power)
wilcoxon_signed_rank_power(n = 50, power = 0.8)

# Framework integration (automatic conversion and discount)
wilcoxon_signed_rank_framework_power(effect_size = 0.5, effect_type = "d", power = 0.8)
```

## Main Functions

### `wilcoxon_signed_rank_power()`
Core power analysis with framework integration.

**Parameters:**

- `r_partial`: Partial correlation coefficient (NULL to calculate)
- `n`: Sample size (NULL to calculate)
- `power`: Statistical power (NULL to calculate, default = 0.8)
- `alpha`: Significance level (default = 0.05)
- `discount_factor`: Conservative discount factor (default = 0.75)
- `two_tailed`: Two-tailed test (default = TRUE)
- `asymptotic`: Use asymptotic approximation (default = TRUE)
- `effect_input`: Raw effect size input (alternative to r_partial)
- `effect_type`: Type of effect_input ("r", "d", "f2", "r_squared", "eta_squared")

### `wilcoxon_signed_rank_framework_power()`
Framework-integrated analysis with automatic conversion.

**Parameters:**

- `effect_size`: Effect size value
- `effect_type`: Type of effect size ("r", "d", "f2", "r_squared", "eta_squared")
- `n`: Sample size (NULL to calculate)
- `power`: Target power (default = 0.8)

### Convenience Functions

- `wilcoxon_sample_size()`: Quick sample size calculation
- `wilcoxon_power_check()`: Quick power calculation

## Framework Integration Examples

### Multiple Effect Size Types
```r
# Cohen's d to framework Wilcoxon
wilcoxon_signed_rank_framework_power(effect_size = 0.5, effect_type = "d", power = 0.8)

# R² to framework Wilcoxon
wilcoxon_signed_rank_framework_power(effect_size = 0.09, effect_type = "r_squared", n = 40)

# Direct partial correlation
wilcoxon_signed_rank_power(r_partial = 0.25, power = 0.8)
```

### Literature Integration
```r
# Convert mixed literature effects to unified framework
effect_sizes <- c(0.3, 0.08, 0.4)  # r, R², Cohen's d
effect_types <- c("r", "r_squared", "d")

# Framework conversion workflow using individual conversions
framework_rs <- sapply(1:length(effect_sizes), function(i) {
  framework_effect_size(effect_sizes[i], effect_types[i], apply_discount = TRUE)
})
```

## Effect Size Guidelines

### Framework Interpretation (Cohen's Standard)

- **r < 0.10**: Negligible effect
- **r = 0.10-0.29**: Small effect
- **r = 0.30-0.49**: Medium effect
- **r ≥ 0.50**: Large effect

### Nonparametric-Specific Metrics

- **Area Under Curve (AUC)**: Probability of superiority
- **Common Language ES**: Percentage of overlap interpretation
- **Rank-biserial correlation**: Nonparametric effect size correlation

### Field-Specific Planning (Cohen's d equivalents)

- **Psychology**: d = 0.4 (r ≈ 0.15 after discount)
- **Medicine**: d = 0.6 (r ≈ 0.23 after discount)
- **Education**: d = 0.3 (r ≈ 0.11 after discount)
- **Social Work**: d = 0.5 (r ≈ 0.19 after discount)

## Sample Size Planning

Use framework power analysis functions to determine sample size requirements for your specific nonparametric design:

```r
# Calculate your specific design requirements
wilcoxon_signed_rank_power(r_partial = 0.25, power = 0.8)

# Compare efficiency with parametric alternatives
linear_regression_power(r_partial = 0.25, power = 0.8, n_predictors = 1)
```

### Asymptotic vs Exact Methods
```r
# Large samples (n > 25): Use asymptotic approximation
wilcoxon_signed_rank_power(r_partial = 0.25, n = 50, asymptotic = TRUE)

# Small samples (n ≤ 25): Use exact calculation
wilcoxon_signed_rank_power(r_partial = 0.25, n = 20, asymptotic = FALSE)
```

### Efficiency Considerations

- **ARE ≈ 0.955**: Wilcoxon is ~95.5% as efficient as t-test for normal data
- **Robust performance**: Superior to t-test for heavy-tailed or skewed distributions
- **Framework comparison**: Direct sample size comparison with parametric methods

## Best Practices

### Framework Workflow

1. **Use framework functions** for all effect size conversions
2. **Apply default discount factor** (0.75) for conservative planning
3. **Leverage auto-detection** by providing any 2 of 3 parameters
4. **Check framework conversions** for cross-method comparison

### When to Choose Wilcoxon

1. **Non-normal distributions**: Skewed, heavy-tailed, or multimodal data
2. **Small samples**: When normality assumptions questionable (n < 30)
3. **Ordinal data**: When ranks more meaningful than raw scores
4. **Outlier robustness**: When extreme values present

### Study Planning

1. **Literature Integration**: Convert all effect sizes to partial correlations
2. **Method Selection**: Asymptotic for n > 25, exact for smaller methods
3. **Conservative Estimates**: Trust framework discount for realistic planning
4. **Directional Testing**: One-tailed tests when direction is theoretically justified

### Quality Assurance

1. **Framework Validation**: All inputs validated by core utilities
2. **Mathematical Accuracy**: ARE adjustments and exact/asymptotic methods
3. **Consistent Interpretation**: Standard Cohen's effect size guidelines
4. **Cross-method Comparison**: Direct comparison with parametric alternatives

## Integration with Unified Framework

### Framework Functions Used

- `framework_effect_size()`: Unified effect size conversion
- `validate_partial_r()`: Input validation
- `framework_conversion_summary()`: Complete effect size report
- `interpret_effect_size()`: Standard interpretation

### Package Integration
This Wilcoxon analysis integrates seamlessly with all other framework methods:

- **Correlation Analysis**: Same effect size metric enables direct comparison
- **Linear Regression**: Unified interpretation across parametric/nonparametric
- **Mediation Analysis**: Consistent effect size framework
- **Multilevel Models**: Shared partial correlation foundation

The nonparametric implementation demonstrates the unified framework's flexibility for robust statistical approaches while maintaining mathematical consistency and interpretive clarity through shared partial correlation metrics, enabling researchers to compare nonparametric effects with parametric alternatives.

## Examples

Essential scenarios demonstrating Wilcoxon signed-rank power analysis within the unified framework using partial correlations for nonparametric testing.

Author: Power Analysis Package
Version: 1.2

### EXAMPLE 1: BASIC FRAMEWORK WORKFLOW

```{r ex1}
# Research: Pre-post intervention effect with non-normal data
# Expected Cohen's d = 0.4 from pilot study

result1 <- wilcoxon_signed_rank_power(
  effect_input = 0.4,
  effect_type = "d",
  n = 50
)
print.wilcoxon_signed_rank_power_analysis(result1)
```

### EXAMPLE 2: SAMPLE SIZE PLANNING WITH FRAMEWORK

```{r ex2}
# Target: 80% power to detect r = 0.25 (medium effect)
result2 <- wilcoxon_signed_rank_power(r_partial = 0.25, power = 0.8)

cat("Sample size needed:", result2$n, "participants\n")
cat("Effect interpretation:", result2$interpretation, "\n\n")
```

### EXAMPLE 3: FRAMEWORK EFFECT SIZE CONVERSIONS

```{r ex3}
# Convert R² = 0.09 to framework analysis
result3 <- wilcoxon_signed_rank_framework_power(
  effect_size = 0.09,
  effect_type = "r_squared",
  n = 30
)

cat("Input R²: 0.09, Framework r:", round(result3$r_partial, 3),
    ", Power:", round(result3$power, 3), "\n")
```

### EXAMPLE 4: AUTO-DETECTION FEATURES

```{r ex4}
# Calculate detectable effect size for n=40, power=0.8
result4 <- wilcoxon_signed_rank_power(n = 40, power = 0.8)

cat("With n=40, 80% power detects r =", round(result4$r_partial, 3),
    "(d =", round(result4$effect_size_conversions$cohens_d, 3), ")\n")
```

### EXAMPLE 5: ASYMPTOTIC VS EXACT METHODS

```{r ex5}
# Compare calculation approaches for small samples
r_fixed <- 0.30
n_small <- 20

asymptotic_result <- wilcoxon_signed_rank_power(r_partial = r_fixed, n = n_small, asymptotic = TRUE)
exact_result <- wilcoxon_signed_rank_power(r_partial = r_fixed, n = n_small, asymptotic = FALSE)

cat("Method comparison (r=0.30, n=20):\n")
cat("Asymptotic: Power =", round(asymptotic_result$power, 3), "\n")
cat("Exact: Power =", round(exact_result$power, 3), "\n")
```

### EXAMPLE 6: FRAMEWORK CONVERSION DEMONSTRATION

```{r ex6}
# Demonstrate framework conversions for Cohen's d values
effect_sizes <- c(0.2, 0.5, 0.8)  # Cohen's d values

cat("Cohen's d to framework conversions:\n")
for (d in effect_sizes) {
  result <- wilcoxon_signed_rank_power(effect_input = d, effect_type = "d", power = 0.8)
  cat("Input d =", d, ": Framework r =", round(result$r_partial, 3), 
      ", Required n =", result$n, "\n")
}
```

### EXAMPLE 7: ONE-TAILED VS TWO-TAILED TESTS

```{r ex7}
# Compare directional vs non-directional testing
r_directional <- 0.20
n_directional <- 35

two_tailed_power <- wilcoxon_signed_rank_power(r_partial = r_directional, n = n_directional, two_tailed = TRUE)
one_tailed_power <- wilcoxon_signed_rank_power(r_partial = r_directional, n = n_directional, two_tailed = FALSE)

cat("Directional testing comparison (r=0.20, n=35):\n")
cat("Two-tailed: Power =", round(two_tailed_power$power, 3), "\n")
cat("One-tailed: Power =", round(one_tailed_power$power, 3), "\n")
```

### EXAMPLE 8: FIELD-SPECIFIC APPLICATIONS

```{r ex8}
# Typical effect sizes by research field (as Cohen's d)
fields <- data.frame(
  Field = c("Psychology", "Medicine", "Education", "Social Work"),
  Typical_d = c(0.4, 0.6, 0.3, 0.5)
)

cat("Sample sizes for 80% power by field:\n")
for (i in 1:nrow(fields)) {
  field_result <- wilcoxon_signed_rank_framework_power(
    effect_size = fields$Typical_d[i],
    effect_type = "d",
    power = 0.8
  )
  cat(fields$Field[i], "(d =", fields$Typical_d[i], "):",
      field_result$n, "participants\n")
}
```

### EXAMPLE 9: CONSERVATIVE VS. OPTIMISTIC PLANNING

```{r ex9}
# Compare framework discount vs. no discount
pilot_d <- 0.5

# Framework approach (with discount)
conservative_result <- wilcoxon_signed_rank_framework_power(
  effect_size = pilot_d,
  effect_type = "d",
  power = 0.8
)

# No discount approach (convert d to r manually)
pilot_r_no_discount <- pilot_d / sqrt(pilot_d^2 + 4)  # Approximate conversion
optimistic_result <- wilcoxon_signed_rank_power(
  r_partial = pilot_r_no_discount,
  power = 0.8
)

cat("Planning comparison for d =", pilot_d, ":\n")
cat("Conservative (framework):", conservative_result$n, "vs Optimistic:", optimistic_result$n,
    "- Safety margin:", conservative_result$n - optimistic_result$n, "\n")
```

### EXAMPLE 10: NONPARAMETRIC EFFECT SIZE INTERPRETATION

```{r ex10}
# Examine nonparametric-specific metrics
result10 <- wilcoxon_signed_rank_power(r_partial = 0.30, n = 50)

cat("Nonparametric effect size metrics for r = 0.30:\n")
np_conv <- result10$nonparametric_conversions
cat("Area Under Curve:", round(np_conv$auc, 3), "\n")
cat("Common Language ES:", round(np_conv$common_language_es * 100, 1), "%\n")
cat("Rank-biserial r:", round(np_conv$rank_biserial_r, 3), "\n")
```

### EXAMPLE 11: LITERATURE INTEGRATION WORKFLOW

```{r ex11}
# Step 1: Literature effects with mixed metrics
literature_effects <- data.frame(
  Study = c("A", "B", "C"),
  Effect = c(0.25, 0.08, 0.4),
  Type = c("r", "r_squared", "d")
)

# Step 2: Convert to framework partial correlations using effect_input parameter
framework_results <- list()
for (i in 1:nrow(literature_effects)) {
  framework_results[[i]] <- wilcoxon_signed_rank_power(
    effect_input = literature_effects$Effect[i],
    effect_type = literature_effects$Type[i],
    power = 0.8
  )
}

# Step 3: Meta-analytic planning
framework_rs <- sapply(framework_results, function(x) x$r_partial)
meta_r <- mean(framework_rs)
meta_result <- wilcoxon_signed_rank_power(r_partial = meta_r, power = 0.8)

cat("Literature integration: Meta-analytic r =", round(meta_r, 3),
    ", Required n =", meta_result$n, "(", meta_result$interpretation, ")\n")
```

### EXAMPLE 12: CROSS-METHOD FRAMEWORK COMPARISON

```{r ex12}
# Compare nonparametric vs parametric approach conceptually
effect_r <- 0.25

# Wilcoxon signed-rank analysis
wilcoxon_result <- wilcoxon_signed_rank_power(r_partial = effect_r, power = 0.8)

cat("Wilcoxon signed-rank analysis for r = 0.25:\n")
cat("Required sample size:", wilcoxon_result$n, "participants\n")
cat("ARE efficiency factor:", round(wilcoxon_result$are_factor, 3), "\n")
cat("Note: Wilcoxon is ~95.5% as efficient as parametric tests for normal data\n")
```

## FRAMEWORK BEST PRACTICES

- Use wilcoxon_signed_rank_framework_power() for automatic conversion
- Apply framework discount factor for conservative planning
- Choose asymptotic method for n > 25, exact for smaller samples
- One-tailed tests require smaller samples when direction is known
- ARE ≈ 0.955 makes Wilcoxon nearly as efficient as t-test for normal data
