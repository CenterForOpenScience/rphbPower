---
title: "Quick Reference Guide"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quick Reference Guide}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(rphbPower)
```

Complete function reference for the unified partial correlation framework with fast lookup of methods, parameters, and common usage patterns.

## Framework Setup

### Quick Start Pattern
```r
# All methods follow unified pattern: provide any 2 of 3 parameters
method_power(r_partial = NULL, n = NULL, power = 0.8, ...)

# Framework integration with automatic effect size conversion
method_power(effect_input = effect_size, effect_type = "d", ...)
```

## Complete Method Reference

| **Analysis Method** | **Function** | **Primary Use Case** | **Key Parameters** |
|-------------------|-------------|-------------------|------------------|
| **Correlation** | `correlation_power()` | Simple X-Y relationships | `r_partial, n, power` |
| **Linear Regression** | `linear_regression_power()` | Multiple predictors, continuous outcome | `r_partial, n, power, n_predictors` |
| **Logistic Regression** | `logistic_regression_power()` | Binary outcomes | `r_partial, n, power, n_predictors` |
| **Cross-Lagged Panel** | `cross_lagged_panel_power()` | Reciprocal causation over time | `r_partial, n, power, n_waves, stability_coefficient` |
| **Fixed Effects** | `fixed_effects_power()` | Panel data, many time points | `r_partial, n_units, power, n_periods` |
| **Repeated Measures** | `repeated_measures_power()` | Within-subjects design | `r_partial, n, power, n_timepoints` |
| **Mediation (Regression)** | `mediation_regression_power()` | Causal pathways X→M→Y | `r_a, r_b, n, power, test_type` |
| **Mediation (SEM)** | `mediation_sem_power()` | Complex mediation models | `r_a, r_b, n, power` |
| **Mixed Models** | `mixed_models_power()` | Nested/clustered data | `r_partial, n_groups, power, n_per_group, icc` |
| **SEM Direct Effects** | `sem_direct_effects_power()` | Structural equation models | `r_partial, n, power, n_predictors` |
| **Nonparametric** | `wilcoxon_signed_rank_power()` | Non-normal, robust analysis | `r_partial, n, power` |

## Unified Framework Features

### Auto-Detection (All Methods)
```r
# Provide any 2 parameters, calculates the 3rd
result <- linear_regression_power(r_partial = 0.25, n = 120, n_predictors = 3)      # → power
result <- linear_regression_power(r_partial = 0.25, power = 0.8, n_predictors = 1)  # → sample size
result <- linear_regression_power(n = 150, power = 0.8, n_predictors = 2)           # → effect size
```

### Framework Effect Size Integration
```r
# Automatic conversion with conservative discount
linear_regression_power(effect_input = 0.4, effect_type = "d", power = 0.8, n_predictors = 3)
linear_regression_power(effect_input = 0.15, effect_type = "f2", power = 0.8, n_predictors = 2)
linear_regression_power(effect_input = 0.09, effect_type = "r_squared", power = 0.8, n_predictors = 1)

# Manual conversion functions
r_partial <- framework_effect_size(0.5, "d", apply_discount = TRUE)
r_partial <- cohens_f2_to_partial_r(0.15, apply_discount = TRUE)
r_partial <- r_squared_to_partial_r(0.09, apply_discount = TRUE)
```

### Statistical Test Conversions
```r
# From existing results
r_partial <- partial_correlation_from_t(t_value = 3.2, df = 147)
r_partial <- partial_correlation_from_f(f_value = 8.5, df_den = 145)
r_partial <- partial_correlation_from_zero_order(r_xy = 0.45, r_xz = 0.30, r_yz = 0.25)
```

## Common Function Patterns

### Linear Regression (Most Common)
```r
# Basic usage
linear_regression_power(r_partial = 0.25, power = 0.8, n_predictors = 1)

# Multiple predictors
linear_regression_power(r_partial = 0.20, power = 0.8, n_predictors = 5)

# Framework integration
linear_regression_power(effect_input = 0.4, effect_type = "d", power = 0.8, n_predictors = 3)

# Convenience functions
linear_regression_sample_size(r_partial = 0.25, power = 0.8, n_predictors = 1)
linear_regression_power_check(r_partial = 0.25, n = 120, n_predictors = 1)
```

### Logistic Regression
```r
# Using partial correlations (framework approach)
logistic_regression_power(r_partial = 0.25, power = 0.8, n_predictors = 1)

# Framework conversion from Cohen's d
logistic_regression_power(effect_input = 0.5, effect_type = "d", power = 0.8, n_predictors = 1)

# Framework conversion from Cohen's f²
logistic_regression_power(effect_input = 0.15, effect_type = "f2", power = 0.8, n_predictors = 2)
```

### Mediation Analysis
```r
# Regression-based mediation
mediation_regression_power(r_a = 0.30, r_b = 0.35, power = 0.8, test_type = "sobel")

# SEM-based mediation
mediation_sem_power(r_a = 0.25, r_b = 0.40, power = 0.8, n_indicators_total = 9)

# Framework integration for both paths
mediation_regression_power(effect_input_a = 0.4, effect_input_b = 0.3, effect_type = "d", power = 0.8)
```

### Mixed Models
```r
# Calculate required number of groups
mixed_models_power(r_partial = 0.20, power = 0.8, n_per_group = 20, icc = 0.05)

# Framework approach
mixed_models_power(effect_input = 0.09, effect_type = "r_squared", power = 0.8, n_per_group = 15)

# Convenience functions
mixed_models_sample_size(r_partial = 0.20, power = 0.8, n_per_group = 20, icc = 0.05)
mixed_models_power_check(r_partial = 0.20, n_groups = 25, n_per_group = 20, icc = 0.05)
```

### Longitudinal Methods
```r
# Cross-lagged panel
cross_lagged_panel_power(r_partial = 0.15, power = 0.8, n_waves = 3, stability_coefficient = 0.6)

# Fixed effects
fixed_effects_power(r_partial = 0.15, power = 0.8, n_periods = 4, icc = 0.3)

# Repeated measures
repeated_measures_power(r_partial = 0.25, power = 0.8, n_timepoints = 3, correlation_between_measures = 0.6)

# Convenience functions
cross_lagged_panel_sample_size(r_partial = 0.15, power = 0.8, n_waves = 3, stability_coefficient = 0.6)
fixed_effects_sample_size(r_partial = 0.15, power = 0.8, n_periods = 4, icc = 0.3)
```

### SEM and Nonparametric
```r
# SEM direct effects
sem_direct_effects_power(r_partial = 0.25, power = 0.8, n_predictors = 4, measurement_reliability = 0.85)

# Nonparametric analysis
wilcoxon_signed_rank_power(r_partial = 0.20, power = 0.8, two_tailed = TRUE)

# Convenience functions
sem_direct_effects_sample_size(r_partial = 0.25, power = 0.8, n_predictors = 4)
wilcoxon_sample_size(r_partial = 0.20, power = 0.8)
```

## Effect Size Guidelines

### Partial Correlations (All Methods)
| **Magnitude** | **r_partial** | **Interpretation** | **Typical Fields** |
|--------------|--------------|------------------|------------------|
| **Negligible** | \|r\| < 0.10 | Very small effect | Medical research baseline |
| **Small** | \|r\| = 0.10-0.29 | Small but meaningful | Psychology, education |
| **Medium** | \|r\| = 0.30-0.49 | Moderate effect | Business, applied research |
| **Large** | \|r\| ≥ 0.50 | Strong effect | Rare in most fields |

### Framework Conversions
| **Input Type** | **Small** | **Medium** | **Large** | **Function** |
|---------------|----------|-----------|-----------|-------------|
| **Cohen's d** | 0.2 | 0.5 | 0.8 | `framework_effect_size(value, "d")` |
| **Cohen's f²** | 0.02 | 0.15 | 0.35 | `framework_effect_size(value, "f2")` |
| **R²** | 0.01 | 0.09 | 0.25 | `framework_effect_size(value, "r_squared")` |
| **Eta²** | 0.01 | 0.06 | 0.14 | `framework_effect_size(value, "eta_squared")` |

## Sample Size Planning

### 80% Power, α = 0.05 (Framework Defaults)
| **Effect Size** | **Correlation** | **Linear Reg (1 pred)** | **Linear Reg (5 pred)** | **Mediation** | **Mixed Models** |
|---------------|---------------|------------------------|------------------------|-------------|----------------|
| **Small (r=0.15)** | ~345 | ~345 | ~375 | ~550 | ~400 (20 groups) |
| **Medium (r=0.25)** | ~122 | ~122 | ~135 | ~200 | ~150 (20 groups) |
| **Large (r=0.40)** | ~46 | ~46 | ~55 | ~80 | ~70 (20 groups) |

### Model Complexity Planning
**Example: r = 0.20, 80% power**
- **1 predictor**: 192 participants
- **5 predictors**: 320 participants (+67%)
- **10 predictors**: 410 participants (+113%)

**Planning Note**: Model complexity significantly impacts sample size requirements. Always specify actual predictor count rather than using simple correlation estimates.

## Parameter Defaults

### Universal Defaults (All Methods)
| **Parameter** | **Default** | **Rationale** |
|--------------|------------|--------------|
| `power` | 0.8 | 80% power standard |
| `alpha` | 0.05 | 5% Type I error rate |
| `discount_factor` | 0.75 | Conservative planning |
| `apply_discount` | TRUE | Realistic effect sizes |

### Method-Specific Defaults
| **Method** | **Special Defaults** | **Notes** |
|-----------|-------------------|----------|
| **Mixed Models** | `icc = 0.05, n_per_group = 10, test_level = "level1"` | Typical clustering |
| **Repeated Measures** | `correlation_between_measures = 0.5` | Moderate correlation |
| **Cross-Lagged** | `stability_coefficient = 0.6, n_waves = 3` | Typical autoregression |
| **Fixed Effects** | `n_periods = 4, icc = 0.3` | Panel data structure |
| **Mediation** | `test_type = "sobel"` | Standard approach |
| **SEM** | `measurement_reliability = 0.85` | Good measurement quality |

## Framework Utilities

### Conversion Functions
```r
# Effect size conversions
unified_effect_size_table(c(0.2, 0.5, 0.8), "d", apply_discount = TRUE)
framework_conversion_summary(0.4, "d", apply_discount = TRUE)

# Validation
validate_partial_r(r_input, allow_zero = FALSE)
interpret_effect_size(0.25, standard = "cohen")

# Sample size adjustments
effective_sample_size(n_nominal = 200, design_effect = 1.5)
```

### Quality Control
```r
# Framework validation
show_available_methods()                    # See loaded methods
framework_quick_start(0.4, "d", "linear_regression")  # Quick analysis
```

## Common Usage Patterns

### Literature Integration
```r
# Step 1: Convert mixed effect sizes
studies <- data.frame(
  effect = c(0.4, 0.12, 0.08),
  type = c("d", "r_squared", "f2")
)

# Step 2: Framework conversion
r_values <- mapply(framework_effect_size, studies$effect, studies$type, 
                   MoreArgs = list(apply_discount = TRUE))

# Step 3: Meta-analytic planning
meta_r <- mean(r_values)
linear_regression_power(r_partial = meta_r, power = 0.8, n_predictors = 3)
```

### Cross-Method Comparison
```r
# Same effect, different methods
effect_r <- 0.25

correlation_power(r_partial = effect_r, power = 0.8)$n
linear_regression_power(r_partial = effect_r, power = 0.8, n_predictors = 1)$n
repeated_measures_power(r_partial = effect_r, power = 0.8, n_timepoints = 2)$n
```

### Sensitivity Analysis
```r
# Multiple scenarios
scenarios <- c(0.15, 0.20, 0.25, 0.30)
sapply(scenarios, function(r) linear_regression_power(r_partial = r, power = 0.8, n_predictors = 3)$n)
```

## Troubleshooting Quick Fixes

### Common Error Messages
| **Error** | **Cause** | **Solution** |
|-----------|-----------|-------------|
| "Provide exactly two parameters" | Wrong number of NULL values | Set exactly 2 of: r_partial, n, power |
| "Partial correlation must be < 1" | Effect size too large | Check effect size input; use framework conversion |
| "Function not found" | Method not loaded | Use `load_analysis_method("method_name")` |
| "Insufficient degrees of freedom" | Sample size too small | Increase n or reduce n_predictors |

### Unrealistic Results
| **Issue** | **Typical Cause** | **Solution** |
|-----------|------------------|--------------|
| N > 2000 for medium effect | Effect size too small | Check framework discount; validate effect size |
| N < 30 for small effect | Effect size too optimistic | Use framework conversion with discount |
| Power < 0.3 with large N | Effect size too small | Reconsider effect size; check literature |

## Quick Decision Support

### Method Selection (30-Second Guide)

1. **Continuous outcome** → `linear_regression_power()`
2. **Binary outcome** → `logistic_regression_power()`
3. **Within-subjects design** → `repeated_measures_power()`
4. **Clustered data** → `mixed_models_power()`
5. **Mediation question** → `mediation_regression_power()`
6. **Longitudinal/causal** → `fixed_effects_power()` or `cross_lagged_panel_power()`
7. **Complex structural model** → `sem_direct_effects_power()`

### Effect Size Selection (30-Second Guide)

1. **Have pilot data** → Use `partial_correlation_from_t()` or similar
2. **Have literature** → Use `framework_effect_size()` with appropriate type
3. **No data** → Psychology: r=0.20; Education: r=0.25; Medicine: r=0.15
4. **Conservative planning** → Use framework defaults (0.75 discount applied automatically)

### Sample Size Reality Check

- **N < 50**: Very large effects only
- **N = 50-150**: Medium to large effects 
- **N = 150-300**: Small to medium effects
- **N > 300**: Small effects detectable

The unified framework enables sophisticated power analysis with simple, consistent function patterns across all statistical methods.
