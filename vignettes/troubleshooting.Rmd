---
title: "Troubleshooting Guide"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Troubleshooting Guide}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(rphbPower)
```

Complete diagnostic and solution guide for power analysis issues within the unified partial correlation framework.

## Framework Overview

The unified framework uses **partial correlations** as the standardized effect size metric across all analysis types, with integrated setup, conservative planning, and cross-method consistency. Most issues arise from setup problems, effect size conversion errors, or unrealistic parameter combinations.

**Core Architecture:**

- **Unified effect sizes**: All analyses use partial correlations for direct comparison
- **Auto-detection**: Provide any 2 of (effect size, sample size, power) - calculates the third
- **Framework integration**: Seamless conversion from Cohen's d, f², R², eta-squared

## Quick Diagnostic Workflow

### Step 1: Verify Method Access & Functionality

```{r step-1}
library(rphbPower)

# Test a basic, valid function call
# This should return a list object, not an error.
test_result <- linear_regression_power(r_partial = 0.25, power = 0.8, n_predictors = 1)
print(test_result)
```

If the steps above work, your setup is correct. You can skip to the Parameter Detection Issues section.

## Setup Issues

## Parameter Detection Issues

*(This section is still accurate and remains unchanged.)*

## Method-Specific Issues

### Linear/Logistic Regression

```r
# ❌ COMMON ERROR (Logistic): Including n_predictors. This is ignored by the engine.
logistic_regression_power(r_partial = 0.25, power = 0.8, n_predictors = 3)

# ✅ SOLUTION (Logistic): The engine assumes a single predictor.
logistic_regression_power(r_partial = 0.25, power = 0.8)

# ✅ CORRECT (Linear): Always specify n_predictors for linear regression.
linear_regression_power(r_partial = 0.20, power = 0.8, n_predictors = 5)
```

### Mediation Analysis

```r
# ❌ COMMON ERROR: Using obsolete parameters like 'test_type'.
mediation_regression_power(r_a = 0.30, r_b = 0.25, power = 0.8, test_type = "sobel")

# ✅ SOLUTION: The engine is now analytical by default. Simply provide the 3 known parameters.
mediation_regression_power(r_a = 0.30, r_b = 0.25, power = 0.8)

# ❌ COMMON ERROR (SEM): Using outdated parameters like 'n_indicators_total'.
mediation_sem_power(r_a = 0.25, r_b = 0.30, n_indicators_total = 9, power = 0.8)

# ✅ SOLUTION (SEM): Use the correct 'measurement_reliability' parameter.
mediation_sem_power(r_a = 0.25, r_b = 0.30, measurement_reliability = 0.9, power = 0.8)
```

### Mixed Models

```r
# ❌ COMMON ERROR: Forgetting the required 'test_level' parameter.
mixed_models_power(r_partial = 0.20, n_groups = 25, power = 0.8)

# ✅ SOLUTION: Specify 'test_level' as either "level1" or "level2".
mixed_models_power(r_partial = 0.20, n_groups = 25, power = 0.8, test_level = "level1")
```

### SEM and Longitudinal Methods

```r
# Correct parameter usage for complex methods:
sem_direct_effects_power(r_partial = 0.25, n_predictors = 4, measurement_reliability = 0.85, power = 0.8)
cross_lagged_panel_power(r_partial = 0.15, n_waves = 3, power = 0.8)
fixed_effects_power(r_partial = 0.15, n_units = 100, n_periods = 4, power = 0.8)
repeated_measures_power(r_partial = 0.25, n_timepoints = 2, power = 0.8)
```

## Unrealistic Results

*(This section is still accurate and remains unchanged.)*

## Cross-Method Integration Issues

*(This section is still accurate and remains unchanged.)*

## Literature Integration Troubleshooting

*(This section is still accurate and remains unchanged.)*

## Advanced Troubleshooting

### Performance Optimization

```r
# For repeated analyses, it can be slightly more efficient to source
# files directly if you only need one or two methods.
source("04_core/compute_partial_correlations.R")
source("05_methods/5.2_regression/linear_regression/linear_regression_power_analysis.R")

# Batch processing example
effect_sizes <- seq(0.15, 0.35, 0.05)
sample_sizes <- sapply(effect_sizes, function(r) {
  linear_regression_power(r_partial = r, power = 0.8, n_predictors = 3)$n
})

results_table <- data.frame(
  Effect_Size = effect_sizes,
  Sample_Size = sample_sizes,
  Interpretation = sapply(effect_sizes, interpret_effect_size)
)
```

## Quality Assurance Checklist

### Before Analysis

- [ ] **Setup system working**: `source("02_setup.R")` runs successfully
- [ ] **Method loaded**: `load_analysis_method()` for your analysis type
- [ ] **Effect size realistic**: Check against effect_size_guidelines.md
- [ ] **Parameters complete**: Exactly 2 of (r_partial, n, power) specified

### During Analysis

- [ ] **Framework integration**: Use `framework_effect_size()` for conversions
- [ ] **Parameter validation**: Check for realistic ranges (e.g., ICC, reliability)
- [ ] **Cross-method consistency**: Compare with similar analyses
- [ ] **Assumption planning**: Consider sample size for assumption validation

### After Analysis

- [ ] **Results documentation**: Record effect size conversions
- [ ] **Sensitivity analysis**: Test alternative effect sizes
- [ ] **Method justification**: Ensure analysis matches statistical plan
- [ ] **Sample size rationale**: Document planning decisions

## Common Error Quick Reference

| **Error Message** | **Probable Cause** | **Quick Solution** |
|------------------|-------------------|-------------------|
| "could not find function X" | Method not loaded or setup failed | Rerun `source("02_setup.R")` then `load_analysis_method()` |
| "Provide exactly two of..." | Wrong parameter count | Specify exactly 2 of: r_partial, n, power |
| "between -1 and 1" | Wrong effect size metric | Use `framework_effect_size()` for conversion |
| "Sample size must be >= X" | Insufficient sample | Increase n or reduce model complexity |
| "unused argument (X)" | Parameter name is wrong or obsolete | Check documentation for correct parameter names |
| "Degrees of freedom" | Model too complex for N | Reduce n_predictors or increase n |

## Framework Best Practices Summary

### Setup and Loading

- **Always use setup system**: `source("02_setup.R")` is the intended interface
- **Load methods explicitly**: `load_analysis_method()` for clarity

### Effect Size Planning

- **Use framework conversions**: `framework_effect_size()` for all conversions
- **Apply conservative planning**: Framework discount factor prevents underpowering
- **Reference field guidelines**: See effect_size_guidelines.md for appropriate ranges
- **Document conversion decisions**: Track original metrics and framework values

### Analysis Execution

- **Follow auto-detection pattern**: Provide exactly 2 of 3 core parameters
- **Use framework integration**: effect_input and effect_type for automatic conversion
- **Cross-validate methods**: Compare similar analyses using same r_partial
- **Plan for assumptions**: See assumption_validation_guide.md for sample size requirements

The unified framework prevents most common power analysis errors through consistent interfaces, realistic effect size conversion, and cross-method integration. When issues arise, they typically involve setup problems, unrealistic effect sizes, or parameter specification errors that this guide addresses systematically.
