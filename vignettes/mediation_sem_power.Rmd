---
title: "Mediation SEM Power Analysis"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Mediation SEM Power Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(rphbPower)
```

Power analysis for SEM-based mediation models using partial correlations within the unified framework with integrated measurement error and model complexity adjustments.

## Overview

SEM-based mediation analysis provides comprehensive latent variable testing of mediation hypotheses, accounting for measurement error and model complexity. All effect sizes are converted to partial correlations for direct comparison across correlation, regression, mediation, and other framework analyses.

## Key Framework Features

- **Unified Effect Size Metric**: All analyses use partial correlations for direct comparison
- **Path Coefficient Integration**: Uses r_a and r_b like mediation regression with SEM complexity
- **Conservative Planning**: Built-in discount factor (default 0.75) for realistic estimates
- **Framework Integration**: Seamless conversion from Cohen's d, f², R², eta-squared
- **SEM Complexity**: Accounts for measurement error and number of indicators

## Quick Start

```r
library(rphbPower)

# Calculate power (provide path coefficients and sample size)
mediation_sem_power(r_a = 0.30, r_b = 0.25, n = 400)

# Calculate sample size (provide path coefficients and power)
mediation_sem_power(r_a = 0.25, r_b = 0.30, power = 0.8)

# Framework integration (automatic conversion and discount)
mediation_sem_framework_power(effect_size_a = 0.5, effect_size_b = 0.4, effect_type = "d", power = 0.8)
```

## Main Functions

### `mediation_sem_power()`
Core power analysis with framework integration.

**Parameters:**

- `r_a`: X → Mediator path coefficient (NULL to calculate)
- `r_b`: Mediator → Y path coefficient (controlling for X)
- `n`: Sample size (NULL to calculate)
- `power`: Statistical power (NULL to calculate, default = 0.8)
- `measurement_error`: Measurement error proportion (default = 0.1)
- `n_indicators_total`: Total number of indicators across latent variables (default = 9)
- `alpha`: Significance level (default = 0.05)
- `discount_factor`: Conservative discount factor (default = 0.75)
- `effect_input_a/b`: Raw effect size inputs (alternative to r_a/r_b)
- `effect_type`: Type of effect inputs ("r", "d", "f2", "r_squared", "eta_squared")

### `mediation_sem_framework_power()`
Framework-integrated analysis with automatic conversion.

**Parameters:**

- `effect_size_a`: Effect size for path a
- `effect_size_b`: Effect size for path b
- `effect_type`: Type of effect sizes ("r", "d", "f2", "r_squared", "eta_squared")
- `n`: Sample size (NULL to calculate)
- `power`: Target power (default = 0.8)

### Convenience Functions

- `mediation_sem_sample_size()`: Quick sample size calculation
- `mediation_sem_power_check()`: Quick power calculation

## Framework Integration Examples

### Multiple Effect Size Types
```r
# Cohen's d to framework SEM mediation
mediation_sem_framework_power(effect_size_a = 0.5, effect_size_b = 0.4, effect_type = "d", power = 0.8)

# R² to framework SEM mediation
mediation_sem_framework_power(effect_size_a = 0.09, effect_size_b = 0.06, effect_type = "r_squared", n = 400)

# Direct partial correlations
mediation_sem_power(r_a = 0.25, r_b = 0.30, power = 0.8)
```

### Cross-Method Efficiency Comparison
```r
# Load framework functions for comparison
source("05_methods/5.4_mediation/mediation_regression/mediation_regression_power_analysis.R")

# Same paths: SEM vs. regression-based mediation
r_a <- 0.25
r_b <- 0.30

# SEM mediation (accounts for measurement error and model complexity)
sem_result <- mediation_sem_power(r_a = r_a, r_b = r_b, power = 0.8, measurement_error = 0.1)

# Regression mediation (framework comparison)
reg_result <- mediation_regression_power(r_a = r_a, r_b = r_b, power = 0.8)

# Efficiency comparison: sem_result$n vs reg_result$n
```

## Effect Size Guidelines

### Framework Interpretation (Cohen's Standard)

- **r < 0.10**: Negligible path effect
- **r = 0.10-0.29**: Small path effect
- **r = 0.30-0.49**: Medium path effect
- **r ≥ 0.50**: Large path effect

### Indirect Effect Interpretation

- **Indirect effect < 0.04**: Small mediation effect
- **Indirect effect = 0.04-0.09**: Medium mediation effect
- **Indirect effect ≥ 0.09**: Large mediation effect

### Field-Specific Planning (Path coefficients)

- **Psychology**: r_a = 0.20-0.35, r_b = 0.25-0.40 (intervention pathways)
- **Education**: r_a = 0.25-0.40, r_b = 0.20-0.35 (learning mechanisms)
- **Health**: r_a = 0.15-0.30, r_b = 0.25-0.45 (behavior change pathways)
- **Marketing**: r_a = 0.30-0.45, r_b = 0.25-0.40 (consumer decision processes)

## Sample Size Planning

SEM mediation models require larger samples than regression-based mediation due to measurement error and model complexity considerations. Use framework power analysis functions to determine precise requirements for your specific design:

```r
# Assess measurement error impact on sample size
mediation_sem_power(r_a = 0.25, r_b = 0.30, power = 0.8, measurement_error = 0.05)
mediation_sem_power(r_a = 0.25, r_b = 0.30, power = 0.8, measurement_error = 0.15)
mediation_sem_power(r_a = 0.25, r_b = 0.30, power = 0.8, measurement_error = 0.25)

# Assess model complexity impact
mediation_sem_power(r_a = 0.25, r_b = 0.30, power = 0.8, n_indicators_total = 6)
mediation_sem_power(r_a = 0.25, r_b = 0.30, power = 0.8, n_indicators_total = 12)
mediation_sem_power(r_a = 0.25, r_b = 0.30, power = 0.8, n_indicators_total = 18)

# Compare with regression-based mediation
mediation_regression_power(r_a = 0.25, r_b = 0.30, power = 0.8)
```

## Best Practices

### Framework Workflow

1. **Use framework functions** for all effect size conversions
2. **Apply default discount factor** (0.75) for conservative planning
3. **Account for SEM complexity** through measurement error and indicators
4. **Check framework conversions** in results for cross-method comparison

### Study Planning

1. **Estimate measurement error** from pilot data or reliability information
2. **Plan indicator structure** balancing model complexity with sample size
3. **Conservative path coefficients** accounting for measurement attenuation
4. **Focus on indirect effects** for substantive interpretation

### Quality Assurance

1. **Framework Validation**: All inputs validated by core utilities
2. **Mathematical Accuracy**: Base R calculations ensure reliability
3. **Consistent Interpretation**: Standard Cohen's effect size guidelines
4. **Cross-method Comparison**: Direct comparison with regression mediation results

## Integration with Unified Framework

### Framework Functions Used

- `framework_effect_size()`: Unified effect size conversion
- `validate_partial_r()`: Input validation
- `framework_conversion_summary()`: Complete effect size report
- `partial_r_to_cohens_f2()`: Framework-consistent conversions

### Package Integration
This SEM mediation analysis integrates seamlessly with all other framework methods:

- **Mediation Regression**: Same r_a and r_b values with added SEM complexity
- **Linear Regression**: Consistent effect size metric for path coefficients
- **SEM Direct Effects**: Framework foundation for complex structural models
- **Multilevel Models**: Unified effect interpretation across nested structures

SEM mediation provides the most comprehensive latent variable approach within the unified framework, with all analyses building on regression principles while maintaining mathematical consistency and interpretive clarity through shared partial correlation metrics that account for measurement error and model complexity.

## Examples

Essential scenarios demonstrating SEM mediation power analysis within the unified framework using partial correlations and SEM complexity factors.

Author: Power Analysis Package
Version: 1.2

### EXAMPLE 1: BASIC FRAMEWORK WORKFLOW

```{r ex1}
# Research: SEM mediation with latent variables
# Expected path coefficients from pilot study

result1 <- mediation_sem_power(
  r_a = 0.30,
  r_b = 0.25,
  power = 0.8,
  measurement_error = 0.1,
  n_indicators_total = 9
)
print(result1)
```

### EXAMPLE 2: FRAMEWORK EFFECT SIZE CONVERSION

```{r ex2}
# Literature reports Cohen's d values for intervention effects

result2 <- mediation_sem_framework_power(
  effect_size_a = 0.5,
  effect_size_b = 0.4,
  effect_type = "d",
  power = 0.8,
  measurement_error = 0.12,
  n_indicators_total = 12
)

cat("Paths: d_a = 0.5 → r_a =", round(result2$r_a, 3), 
    ", d_b = 0.4 → r_b =", round(result2$r_b, 3), 
    ", Required n =", result2$n, "\n")
```

### EXAMPLE 3: MEASUREMENT ERROR IMPACT

```{r ex3}
# How measurement error affects sample size requirements

base_r_a <- 0.25
base_r_b <- 0.30
error_levels <- c(0.05, 0.15, 0.25)

cat("Sample size by measurement error level:\n")
for (error in error_levels) {
  result <- mediation_sem_power(r_a = base_r_a, r_b = base_r_b, power = 0.8,
                                measurement_error = error, n_indicators_total = 9)
  cat("Error =", error, ": n =", result$n, 
      " (complexity =", round(result$sem_complexity_factor, 2), ")\n")
}
```

### EXAMPLE 4: CROSS-METHOD EFFICIENCY COMPARISON

```{r ex4}
# Same paths: SEM vs. regression-based mediation

r_a <- 0.25
r_b <- 0.30

# SEM mediation (accounts for measurement error)
sem_result <- mediation_sem_power(r_a = r_a, r_b = r_b, power = 0.8,
                                  measurement_error = 0.1, n_indicators_total = 9)

cat("SEM mediation analysis (r_a =", r_a, ", r_b =", r_b, "):\n")
cat("Required sample size:", sem_result$n, "participants\n")
cat("SEM complexity factor:", round(sem_result$sem_complexity_factor, 2), "\n")
cat("Note: SEM accounts for measurement error and latent variable complexity\n")
```

### EXAMPLE 5: MODEL COMPLEXITY PLANNING

```{r ex5}
# Different numbers of indicators and complexity

indicator_scenarios <- c(6, 9, 12, 15)
effect_r_a <- 0.20
effect_r_b <- 0.25

cat("Sample sizes for r_a = 0.20, r_b = 0.25:\n")
for (indicators in indicator_scenarios) {
  result <- mediation_sem_power(r_a = effect_r_a, r_b = effect_r_b, power = 0.8,
                                measurement_error = 0.1, n_indicators_total = indicators)
  cat(indicators, "indicators:", result$n, "\n")
}
```

### EXAMPLE 6: FIELD-SPECIFIC APPLICATIONS

```{r}
# Typical path coefficients and complexity by research area

fields <- data.frame(
  Field = c("Psychology", "Education", "Health", "Marketing"),
  Path_a = c(0.25, 0.30, 0.20, 0.35),
  Path_b = c(0.28, 0.25, 0.32, 0.30),
  Indicators = c(9, 12, 9, 15),
  Error = c(0.10, 0.12, 0.08, 0.15)
)

cat("Sample sizes for 80% power by field:\n")
for (i in 1:nrow(fields)) {
  result <- mediation_sem_power(
    r_a = fields$Path_a[i],
    r_b = fields$Path_b[i],
    power = 0.8,
    measurement_error = fields$Error[i],
    n_indicators_total = fields$Indicators[i]
  )
  cat(fields$Field[i], "(a =", fields$Path_a[i], ", b =", fields$Path_b[i], "):", result$n, "\n")
}
```

### EXAMPLE 7: PILOT TO MAIN STUDY SCALING

```{r ex7}
# Conservative planning from pilot data

pilot_r_a <- 0.35  # Optimistic pilot results
pilot_r_b <- 0.40
conservative_planning <- mediation_sem_framework_power(
  effect_size_a = pilot_r_a,
  effect_size_b = pilot_r_b,
  effect_type = "r",  # Framework applies 0.75 discount automatically
  power = 0.8,
  measurement_error = 0.12,
  n_indicators_total = 12
)

cat("Pilot paths: a =", pilot_r_a, ", b =", pilot_r_b, 
    "→ Planning: a =", round(conservative_planning$r_a, 3), 
    ", b =", round(conservative_planning$r_b, 3), 
    ", Required n =", conservative_planning$n, "\n")
```

### EXAMPLE 8: INDIRECT EFFECT PLANNING

```{r ex8}
# Focus on indirect effect size for planning

target_indirect_effects <- c(0.06, 0.10, 0.15)  # Small, medium, large indirect effects

for (indirect in target_indirect_effects) {
  # Balanced paths that produce target indirect effect
  balanced_r <- sqrt(indirect)  # Equal paths: a × b = indirect
  
  result <- mediation_sem_power(r_a = balanced_r, r_b = balanced_r, power = 0.8,
                                measurement_error = 0.1, n_indicators_total = 9)
  
  cat("Indirect effect =", indirect, " (a = b =", round(balanced_r, 3), "): n =", result$n, "\n")
}
```

### EXAMPLE 9: FRAMEWORK CONVERSION DEMONSTRATION

```{r ex9}
# Multiple path combinations for planning comparison

path_combinations <- data.frame(
  r_a = c(0.20, 0.30, 0.25),
  r_b = c(0.25, 0.20, 0.30)
)

for (i in 1:nrow(path_combinations)) {
  result <- mediation_sem_power(r_a = path_combinations$r_a[i], 
                                r_b = path_combinations$r_b[i], 
                                power = 0.8, measurement_error = 0.1, 
                                n_indicators_total = 9)
  indirect <- result$indirect_effect
  cat("Paths (", path_combinations$r_a[i], ",", path_combinations$r_b[i], 
      "): indirect =", round(indirect, 3), ", n =", result$n, "\n")
}
```

### EXAMPLE 10: LITERATURE INTEGRATION WORKFLOW

```{r ex10}
# Multiple studies with different effect metrics (convert individually)

studies <- data.frame(
  Study = c("A", "B", "C"),
  Effect_a = c(0.4, 0.09, 0.25),  # d, R², direct r
  Effect_b = c(0.35, 0.06, 0.30),
  Type_a = c("d", "r_squared", "r"),
  Type_b = c("d", "r_squared", "r"),
  Indicators = c(9, 12, 9),
  Error = c(0.10, 0.12, 0.08)
)

# Convert each study individually to framework partial correlations
framework_results <- list()
for (i in 1:nrow(studies)) {
  # Convert a-path and b-path separately
  r_a_converted <- framework_effect_size(studies$Effect_a[i], studies$Type_a[i], apply_discount = TRUE)
  r_b_converted <- framework_effect_size(studies$Effect_b[i], studies$Type_b[i], apply_discount = TRUE)
  
  # Use converted values in power analysis
  framework_results[[i]] <- mediation_sem_power(
    r_a = r_a_converted,
    r_b = r_b_converted,
    power = 0.8,
    measurement_error = studies$Error[i],
    n_indicators_total = studies$Indicators[i]
  )
}

# Meta-analytic planning
framework_a_paths <- sapply(framework_results, function(x) x$r_a)
framework_b_paths <- sapply(framework_results, function(x) x$r_b)
meta_r_a <- mean(framework_a_paths)
meta_r_b <- mean(framework_b_paths)
meta_indicators <- round(mean(studies$Indicators))
meta_error <- mean(studies$Error)

meta_result <- mediation_sem_power(
  r_a = meta_r_a,
  r_b = meta_r_b,
  power = 0.8,
  measurement_error = meta_error,
  n_indicators_total = meta_indicators
)

cat("Literature integration: Meta a =", round(meta_r_a, 3), 
    ", Meta b =", round(meta_r_b, 3), 
    ", Required n =", meta_result$n, "\n")
```

## FRAMEWORK BEST PRACTICES

- Use mediation_sem_framework_power() for automatic conversion and discount
- Higher measurement error and more indicators require larger samples
- Framework partial correlations enable comparison with regression mediation
- SEM mediation provides comprehensive latent variable approach
- Conservative planning with 0.75 discount handles optimistic pilot effects
