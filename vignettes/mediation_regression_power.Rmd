---
title: "Mediation Regression Power Analysis"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Mediation Regression Power Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
devtools::load_all()
```

Power analysis for mediation models using partial correlations within the unified framework with integrated discount factor system and dual-path analysis capabilities.

## Overview

Mediation analysis examines indirect effects through sequential pathways (X→M→Y), extending the unified framework to complex causal processes. All path coefficients are expressed as partial correlations for direct comparison across correlation, linear regression, and other framework analyses.

## Key Framework Features

- **Unified Effect Size Metric**: All path coefficients use partial correlations for direct comparison
- **Automatic Parameter Detection**: Provide any three of (r_a, r_b, n, power) - the fourth is calculated
- **Conservative Planning**: Built-in discount factor (default 0.75) for realistic estimates
- **Framework Integration**: Seamless conversion from Cohen's d, f², R² for both paths
- **Dual-Path Analysis**: Handles sequential X→M→Y pathway complexity

## Quick Start

```{r setup}
library(rphbPower)
```

```r
# Calculate power (provide both paths and n)
mediation_regression_power(r_a = 0.30, r_b = 0.25, n = 200)

# Calculate sample size (provide both paths and power)
mediation_regression_power(r_a = 0.20, r_b = 0.30, power = 0.8)

# Calculate required a-path (provide b-path, n, power)
mediation_regression_power(r_b = 0.25, n = 300, power = 0.8)

# Framework integration (automatic conversion and discount)
mediation_framework_power(effect_size_a = 0.5, effect_size_b = 0.4, effect_type = "d", power = 0.8)
```

## Main Functions

### `mediation_regression_power()`
Core power analysis with framework integration.

**Parameters:**

- `r_a`: A-path coefficient (X→M) as correlation (NULL to calculate)
- `r_b`: B-path coefficient (M→Y|X) as partial correlation (NULL to calculate)
- `n`: Sample size (NULL to calculate)
- `power`: Statistical power (NULL to calculate, default = 0.8)
- `alpha`: Significance level (default = 0.05)
- `discount_factor`: Conservative discount factor (default = 0.75)
- `test_type`: Type of mediation test ("sobel", "joint")
- `effect_input_a`: Raw effect size input for a-path (alternative to r_a)
- `effect_input_b`: Raw effect size input for b-path (alternative to r_b)
- `effect_type`: Type of effect inputs ("r", "d", "f2", "r_squared", "eta_squared")

### `mediation_framework_power()`
Framework-integrated analysis with automatic conversion.

**Parameters:**

- `effect_size_a`: A-path effect size value
- `effect_size_b`: B-path effect size value
- `effect_type`: Type of effect sizes ("r", "d", "f2", "r_squared", "eta_squared")
- `n`: Sample size (NULL to calculate)
- `power`: Target power (default = 0.8)

### Convenience Functions

- `mediation_sample_size()`: Quick sample size calculation
- `mediation_power_check()`: Quick power calculation

## Framework Integration Examples

### Multiple Effect Size Types
```r
# Cohen's d to framework mediation
mediation_framework_power(effect_size_a = 0.5, effect_size_b = 0.4, effect_type = "d", power = 0.8)

# Mixed effect types through main function
mediation_regression_power(
  effect_input_a = 0.12, effect_input_b = 0.4, 
  effect_type = "d", power = 0.8
)

# Direct partial correlations
mediation_regression_power(r_a = 0.25, r_b = 0.30, power = 0.8)
```

### Literature Integration
```r
# Convert mixed literature effects to unified framework
literature_effects <- data.frame(
  Study = c("A", "B", "C"),
  A_path = c(0.3, 0.5, 0.15),    # r, Cohen's d, f²
  B_path = c(0.25, 0.4, 0.08),   # r, Cohen's d, f²
  A_type = c("r", "d", "f2"),
  B_type = c("r", "d", "f2")
)

# Individual conversions for meta-analysis
framework_results <- list()
for (i in 1:nrow(literature_effects)) {
  framework_results[[i]] <- mediation_regression_power(
    effect_input_a = literature_effects$A_path[i], 
    effect_input_b = literature_effects$B_path[i],
    effect_type = literature_effects$A_type[i], 
    power = 0.8
  )
}
```

## Effect Size Guidelines

### Framework Interpretation (Cohen's Standard)

- **Individual paths**: r < 0.10 (Negligible), 0.10-0.29 (Small), 0.30-0.49 (Medium), ≥0.50 (Large)
- **Indirect effects**: ab < 0.01 (Negligible), 0.01-0.09 (Small), 0.09-0.25 (Medium), ≥0.25 (Large)

### Field-Specific Planning (Cohen's d equivalents)

- **Psychology**: d = 0.4, 0.5 (r ≈ 0.15, 0.19 after discount)
- **Education**: d = 0.6, 0.4 (r ≈ 0.23, 0.15 after discount)
- **Health**: d = 0.3, 0.6 (r ≈ 0.11, 0.23 after discount)
- **Organizational**: d = 0.5, 0.3 (r ≈ 0.19, 0.11 after discount)

## Sample Size Planning

Mediation analysis requires precise calculation based on both path coefficients and test type. Use framework power analysis functions to determine sample size requirements for your specific design:

```r
# Calculate for your specific path coefficients
mediation_regression_power(r_a = 0.25, r_b = 0.25, power = 0.8)

# Compare different path combinations
mediation_regression_power(r_a = 0.30, r_b = 0.20, power = 0.8)
mediation_regression_power(r_a = 0.15, r_b = 0.30, power = 0.8)

# Compare with single-path analyses
linear_regression_power(r_partial = 0.25, power = 0.8, n_predictors = 1)
```

### Test Type Comparison

- **Sobel test**: More powerful for medium/large effects, assumes normality
- **Joint significance**: More conservative, tests both paths individually

## Best Practices

### Framework Workflow

1. **Use framework functions** for all effect size conversions
2. **Apply default discount factor** (0.75) for conservative planning
3. **Leverage auto-detection** by providing any 3 of 4 parameters
4. **Check framework conversions** for cross-method comparison

### Study Planning

1. **Literature Integration**: Convert all effect sizes to partial correlations
2. **Sequential Complexity**: Account for mediation's dual-path requirements
3. **Path Balance**: Balanced path coefficients typically yield higher power than unbalanced
4. **Conservative Estimates**: Trust framework discount for realistic planning
5. **Actual Calculations**: Always use framework functions rather than rules of thumb

### Quality Assurance

1. **Framework Validation**: All inputs validated by core utilities
2. **Mathematical Accuracy**: Sobel test and joint significance implementations
3. **Consistent Interpretation**: Standard Cohen's effect size guidelines applied to both paths
4. **Cross-method Comparison**: Direct comparison with regression, correlation results through unified metrics

## Integration with Unified Framework

### Framework Functions Used

- `framework_effect_size()`: Unified effect size conversion for both paths
- `validate_partial_r()`: Input validation for both a-path and b-path
- `framework_conversion_summary()`: Complete effect size reports for both paths
- `interpret_effect_size()`: Standard interpretation for indirect effects

### Package Integration
This mediation analysis integrates seamlessly with all other framework methods:

- **Linear Regression**: B-path analysis equivalent to regression with single predictor
- **Correlation Analysis**: A-path analysis equivalent to bivariate correlation
- **SEM**: Foundation for structural equation mediation models
- **Multilevel Models**: Unified effect interpretation across hierarchical mediation

## Advanced Applications

### Path Coefficient Interpretation
```r
# Calculate and interpret path coefficients
result <- mediation_regression_power(r_a = 0.30, r_b = 0.25, power = 0.8)

# Individual path interpretations
interpret_effect_size(result$r_a)  # A-path interpretation
interpret_effect_size(result$r_b)  # B-path interpretation

# Indirect effect interpretation
indirect_interpretation <- interpret_mediation_effect(result$r_a, result$r_b)
```

### Cross-Method Validation
```r
# Compare mediation with direct effect analysis
direct_effect <- linear_regression_power(r_partial = 0.20, power = 0.8, n_predictors = 1)
mediation_effect <- mediation_regression_power(r_a = 0.30, r_b = 0.25, power = 0.8)

# Framework enables direct comparison of sample size requirements
```

## Troubleshooting Common Issues

### Unrealistic Path Combinations

- **Problem**: Very small indirect effects requiring enormous samples
- **Solution**: Reconsider theoretical model or increase path coefficients based on stronger theory

### Unbalanced Path Coefficients

- **Problem**: One very strong path, one very weak path
- **Solution**: Consider direct effect models or strengthen theoretical justification for weak path

### Power vs. Precision Trade-offs

- **Problem**: Adequate power for existence of indirect effect but poor precision for effect size estimation
- **Solution**: Plan for confidence interval precision in addition to power considerations

Mediation analysis demonstrates the unified framework's capability for complex sequential processes while maintaining mathematical consistency and interpretive clarity through shared partial correlation metrics, enabling researchers to compare mediation effects with other analytical approaches using precise, framework-calculated sample sizes.

## Examples

Essential scenarios demonstrating mediation regression power analysis within the unified framework using partial correlations for both paths.

Author: Power Analysis Package
Version: 1.2

### EXAMPLE 1: BASIC FRAMEWORK WORKFLOW

```{r ex1}
# Research: Does self-efficacy mediate training → job performance?
# Expected a-path (training → self-efficacy): r = 0.30
# Expected b-path (self-efficacy → performance | training): r = 0.25

result1 <- mediation_regression_power(r_a = 0.30, r_b = 0.25, n = 200)
print.mediation_regression_power_analysis(result1)
```

### EXAMPLE 2: SAMPLE SIZE PLANNING WITH FRAMEWORK

```{r ex2}
# Target: 80% power to detect mediation
# A-path = 0.20, B-path = 0.30

result2 <- mediation_regression_power(r_a = 0.20, r_b = 0.30, power = 0.8)

cat("Sample size needed:", result2$n, "participants\n")
cat("Indirect effect:", round(result2$indirect_effect, 3), "\n")
cat("Effect interpretation:", result2$interpretation, "\n")
```

### EXAMPLE 3: FRAMEWORK EFFECT SIZE CONVERSIONS

```{r ex3}
# Convert Cohen's d effects to framework mediation

result3 <- mediation_framework_power(
  effect_size_a = 0.5,  # Cohen's d for a-path
  effect_size_b = 0.4,  # Cohen's d for b-path
  effect_type = "d",
  power = 0.8
)

cat("d = 0.5, 0.4 → Framework r =", round(result3$r_a, 3), ",", round(result3$r_b, 3),
    ", Required n =", result3$n, "\n")
```

### EXAMPLE 4: DETECTABLE EFFECT SIZE ANALYSIS

```{r ex4}
# Study constraints: 300 participants, b-path = 0.25, want 80% power

result4 <- mediation_regression_power(r_b = 0.25, n = 300, power = 0.8)

cat("With n=300, b=0.25, 80% power needs a-path r =", round(result4$r_a, 3), "\n")

# Alternative: Given a-path, what b-path is needed?
result4b <- mediation_regression_power(r_a = 0.20, n = 300, power = 0.8)
cat("With n=300, a=0.20, 80% power needs b-path r =", round(result4b$r_b, 3), "\n")
```

### EXAMPLE 5: MEDIATION TEST TYPE COMPARISON

```{r ex5}
# Compare Sobel vs Joint significance tests

r_a_fixed <- 0.25
r_b_fixed <- 0.20
n_fixed <- 150

cat("Test type comparison (a=0.25, b=0.20, n=150):\n")
for (test_type in c("sobel", "joint")) {
  power_result <- mediation_regression_power(r_a = r_a_fixed, r_b = r_b_fixed, 
                                             n = n_fixed, test_type = test_type)
  cat(test_type, "test: Power =", round(power_result$power, 3), "\n")
}
```

### EXAMPLE 6: FIELD-SPECIFIC APPLICATIONS

```{r ex6}
# Typical effect sizes by research field (as Cohen's d equivalents)

fields <- data.frame(
  Field = c("Psychology", "Education", "Health", "Organizational"),
  A_path_d = c(0.4, 0.6, 0.3, 0.5),
  B_path_d = c(0.5, 0.4, 0.6, 0.3)
)

cat("Sample sizes for 80% power by field:\n")
for (i in 1:nrow(fields)) {
  field_result <- mediation_framework_power(
    effect_size_a = fields$A_path_d[i],
    effect_size_b = fields$B_path_d[i],
    effect_type = "d",
    power = 0.8
  )
  cat(fields$Field[i], "(d =", fields$A_path_d[i], ",", fields$B_path_d[i], "):",
      field_result$n, "participants\n")
}
```

### EXAMPLE 7: CONSERVATIVE VS. OPTIMISTIC PLANNING

```{r ex7}
# Compare framework discount vs. no discount

pilot_a <- 0.45
pilot_b <- 0.35

# Framework approach (with discount)
conservative_result <- mediation_framework_power(
  effect_size_a = pilot_a,
  effect_size_b = pilot_b,
  effect_type = "r",
  power = 0.8
)

# No discount approach using manual conversion
optimistic_a <- framework_effect_size(pilot_a, "r", apply_discount = FALSE)
optimistic_b <- framework_effect_size(pilot_b, "r", apply_discount = FALSE)
optimistic_result <- mediation_regression_power(
  r_a = optimistic_a,
  r_b = optimistic_b,
  power = 0.8
)

cat("Planning comparison for pilot effects a=0.45, b=0.35:\n")
cat("Conservative (framework):", conservative_result$n, "vs Optimistic:", optimistic_result$n,
    "- Safety margin:", conservative_result$n - optimistic_result$n, "\n")
```

### EXAMPLE 8: PATH COEFFICIENT BALANCE ANALYSIS

```{r ex8}
# Effect of balancing vs. unbalancing path coefficients

total_indirect <- 0.12
sample_size <- 180

# Balanced paths (equal strength)
balanced_r <- sqrt(total_indirect)
balanced_power <- mediation_power_check(r_a = balanced_r, r_b = balanced_r, n = sample_size)

# Unbalanced paths (strong a-path, weak b-path)
unbalanced_a <- 0.50
unbalanced_b <- total_indirect / unbalanced_a
unbalanced_power <- mediation_power_check(r_a = unbalanced_a, r_b = unbalanced_b, n = sample_size)

cat("Path balance analysis (indirect = 0.12, n = 180):\n")
cat("Balanced (r =", round(balanced_r, 3), "each): Power =", round(balanced_power, 3), "\n")
cat("Unbalanced (a =", unbalanced_a, ", b =", round(unbalanced_b, 3), "): Power =", 
    round(unbalanced_power, 3), "\n")
```

### EXAMPLE 9: FRAMEWORK CONVERSION DEMONSTRATION

```{r ex9}
# Demonstrate framework conversions for mediation paths

a_path_effects <- c(0.20, 0.30, 0.40)  # A-path correlations

cat("Framework conversions for mediation a-paths:\n")
for (r in a_path_effects) {
  result <- mediation_regression_power(r_a = r, r_b = 0.25, power = 0.8)
  cat("Input r =", r, ": d =", round(result$a_path_conversions$cohens_d, 3), 
      ", R² =", round(result$a_path_conversions$r_squared, 3), "\n")
}
```

### EXAMPLE 10: LITERATURE INTEGRATION WORKFLOW

```{r ex10}
# Step 1: Literature review with mixed effect sizes

literature_effects <- data.frame(
  Study = c("A", "B", "C"),
  A_path = c(0.3, 0.5, 0.15),  # r, Cohen's d, f²
  B_path = c(0.25, 0.4, 0.08), # r, Cohen's d, f²
  A_type = c("r", "d", "f2"),
  B_type = c("r", "d", "f2")
)

# Step 2: Convert to framework partial correlations using main function
framework_results <- list()
for (i in 1:nrow(literature_effects)) {
  framework_results[[i]] <- mediation_regression_power(
    effect_input_a = literature_effects$A_path[i], 
    effect_input_b = literature_effects$B_path[i],
    effect_type = literature_effects$A_type[i], 
    power = 0.8
  )
}

# Step 3: Meta-analytic planning
framework_a_paths <- sapply(framework_results, function(x) x$r_a)
framework_b_paths <- sapply(framework_results, function(x) x$r_b)
meta_a <- mean(framework_a_paths)
meta_b <- mean(framework_b_paths)
meta_result <- mediation_regression_power(r_a = meta_a, r_b = meta_b, power = 0.8)

cat("Literature integration: Meta a =", round(meta_a, 3), ", Meta b =", round(meta_b, 3),
    ", Required n =", meta_result$n, "\n")
```

### EXAMPLE 11: CROSS-METHOD FRAMEWORK CONSISTENCY

```{r ex11}
# Compare mediation b-path with equivalent linear regression

b_path_effect <- 0.25

# Mediation analysis (b-path)
mediation_result <- mediation_regression_power(r_a = 0.30, r_b = b_path_effect, power = 0.8)

cat("Mediation analysis for b-path r = 0.25:\n")
cat("Required sample size:", mediation_result$n, "participants\n")
cat("Note: b-path represents partial correlation controlling for a-path\n")
```

## FRAMEWORK BEST PRACTICES

- Use mediation_framework_power() for automatic effect size conversion
- Framework enables direct comparison with regression and correlation results
- Sobel test generally more powerful than joint significance for small effects
- Balanced path coefficients typically yield higher power than unbalanced
- Conservative planning accounts for mediation's sequential pathway complexity
